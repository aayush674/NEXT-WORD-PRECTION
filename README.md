# NEXT-WORD-PRECTION
Developed a generative model for next-word generation using voice input.  Utilized Long Short-Term Memory (LSTM) Recurrent Neural Network (RNN) architecture to accurately predict the next word in a sequence. Trained on a dataset comprising over 50,000 words, ensuring robust language model performance and accuracy in word prediction tasks.
